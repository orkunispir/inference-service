apiVersion: v1
kind: Service
metadata:
  name: inference-service
  namespace: modeling
spec:
  type: LoadBalancer
  selector:
    app: inference-pod  # This matches the label of your Pod
  ports:
    - protocol: TCP
      port: 8000  # External port exposed by the LoadBalancer (you can choose any port here)
      targetPort: 8000  # The port your application listens on inside the Pod