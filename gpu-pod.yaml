apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-deployment
  namespace: modeling
  labels:
    app: inference-pod
spec:
  replicas: 1  # You can adjust the number of replicas as needed
  selector:
    matchLabels:
      app: inference-pod
  template:
    metadata:
      labels:
        app: inference-pod
    spec:
      containers:
        - name: inference-container
          image: orkunispir/inference-service:latest
          resources:
            limits:
              nvidia.com/gpu: 1
          ports:
            - containerPort: 8000
          env:
            - name: MARIADB_SERVICE_HOST
              value: "mariadb.modeling"
            - name: MARIADB_SERVICE_PORT
              value: "3306"
            - name: MARIADB_USER
              valueFrom:
                configMapKeyRef:
                  name: mariadb-configmap
                  key: MYSQL_USER
            - name: MARIADB_PASSWORD
              valueFrom:
                configMapKeyRef:
                  name: mariadb-configmap
                  key: MYSQL_PASSWORD
            - name: MARIADB_DATABASE
              valueFrom:
                configMapKeyRef:
                  name: mariadb-configmap
                  key: MYSQL_DATABASE
            - name: MINIO_SERVICE_HOST
              value: "minio-api.modeling"
            - name: MINIO_SERVICE_PORT
              value: "9000"
            - name: MINIO_ACCESS_KEY
              valueFrom:
                configMapKeyRef:
                  name: minio-configmap
                  key: MINIO_ROOT_USER
            - name: MINIO_SECRET_KEY
              valueFrom:
                configMapKeyRef:
                  name: minio-configmap
                  key: MINIO_ROOT_PASSWORD
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule